[
  {
    "objectID": "social-variables.html",
    "href": "social-variables.html",
    "title": "Social variables in the use of requests",
    "section": "",
    "text": "import pandas as pd\nimport altair as alt\n\n\nutterances = (pd.read_csv('../in/stat-report/corpus_sent_request_classification_config05.csv')\n .query('training == 1')\n)\n\nlen(utterances)\n\n49997\n\n\nreplace unknown values with NaN\n\nutterances = utterances.assign(\n    age=lambda df: df['age'].replace('Unknown', pd.NA),\n    education=lambda df: df['education'].replace('9_unknown', pd.NA),\n    socGrade=lambda df: df['socGrade'].replace('unknown', pd.NA)\n)\n\n\nage\n\nvariable = 'age'\n\n\ndef get_total_counts (utterances: pd.DataFrame, variable: str) -&gt; pd.DataFrame:\n    return (utterances\n    .value_counts(variable)\n    .reset_index().sort_values(variable)\n    )\n\n\ncounts_all = get_total_counts(utterances, variable)\ncounts_all\n\n\n\n\n\n\n\n\nage\ncount\n\n\n\n\n7\n0_10\n556\n\n\n5\n11_18\n2359\n\n\n0\n19_29\n21622\n\n\n3\n30_39\n5929\n\n\n1\n40_49\n8519\n\n\n2\n50_59\n6452\n\n\n4\n60_69\n2721\n\n\n6\n70_79\n1123\n\n\n8\n80_89\n67\n\n\n\n\n\n\n\n\ndef get_var_counts_requests(utterances: pd.DataFrame, variable: str) -&gt; pd.DataFrame:\n    requests = utterances.query('labels_preds == 1')\n    return (requests\n    .value_counts(variable)\n    .reset_index().sort_values(variable)\n    )\n\n\ncounts_requests = get_var_counts_requests(utterances, variable)\ncounts_requests\n\n\n\n\n\n\n\n\nage\ncount\n\n\n\n\n7\n0_10\n8\n\n\n5\n11_18\n22\n\n\n0\n19_29\n165\n\n\n2\n30_39\n50\n\n\n3\n40_49\n41\n\n\n1\n50_59\n53\n\n\n4\n60_69\n26\n\n\n6\n70_79\n11\n\n\n8\n80_89\n1\n\n\n\n\n\n\n\n\ndef merge_counts(df1: pd.DataFrame, df2: pd.DataFrame, variable: str) -&gt; pd.DataFrame:\n    return (pd.merge(df1, df2, on=variable, how='outer', suffixes=('_all', '_requests'))\n        .assign(requests_rate = lambda df: df['count_requests'] / df['count_all'] * 100)\n    )\n\n\ncounts_merged = merge_counts(counts_all, counts_requests, variable)\ncounts_merged\n\n\n\n\n\n\n\n\nage\ncount_all\ncount_requests\nrequests_rate\n\n\n\n\n0\n0_10\n556\n8\n1.438849\n\n\n1\n11_18\n2359\n22\n0.932599\n\n\n2\n19_29\n21622\n165\n0.763112\n\n\n3\n30_39\n5929\n50\n0.843313\n\n\n4\n40_49\n8519\n41\n0.481277\n\n\n5\n50_59\n6452\n53\n0.821451\n\n\n6\n60_69\n2721\n26\n0.955531\n\n\n7\n70_79\n1123\n11\n0.979519\n\n\n8\n80_89\n67\n1\n1.492537\n\n\n\n\n\n\n\n\nchart = alt.Chart(counts_merged).mark_bar().encode(\n    x=variable,\n    y='requests_rate'\n)\n\nchart\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n\n\n\n\n\n\n\n\n\n# chart.save(f'../out/request-rate_{variable}.png', scale_factor=3.0)\n\n\n\ngender\n\nvariable = 'gender'\n\n\ncounts_all = get_total_counts(utterances, variable)\ncounts_all\n\n\n\n\n\n\n\n\ngender\ncount\n\n\n\n\n0\nF\n29731\n\n\n1\nM\n20255\n\n\n2\nX\n11\n\n\n\n\n\n\n\n\ncounts_requests = get_var_counts_requests(utterances, variable)\ncounts_requests\n\n\n\n\n\n\n\n\ngender\ncount\n\n\n\n\n0\nF\n220\n\n\n1\nM\n163\n\n\n\n\n\n\n\n\ncounts_merged = merge_counts(counts_all, counts_requests, variable)\ncounts_merged\n\n\n\n\n\n\n\n\ngender\ncount_all\ncount_requests\nrequests_rate\n\n\n\n\n0\nF\n29731\n220.0\n0.739968\n\n\n1\nM\n20255\n163.0\n0.804740\n\n\n2\nX\n11\nNaN\nNaN\n\n\n\n\n\n\n\n\nchart = alt.Chart(counts_merged).mark_bar().encode(\n    x=variable,\n    y='requests_rate'\n)\n\nchart\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n\n\n\n\n\n\n\n\n\n# chart.save(f'../out/request-rate_{variable}.png', scale_factor=3.0)\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n\n\n\n\neducation\n\nvariable = 'education'\n\n\ncounts_all = get_total_counts(utterances, variable)\ncounts_all\n\n\n\n\n\n\n\n\neducation\ncount\n\n\n\n\n4\n1_primary\n59\n\n\n3\n2_secondary\n4736\n\n\n2\n3_sixthform\n10501\n\n\n0\n4_graduate\n21165\n\n\n1\n5_postgrad\n11797\n\n\n\n\n\n\n\n\ncounts_requests = get_var_counts_requests(utterances, variable)\ncounts_requests\n\n\n\n\n\n\n\n\neducation\ncount\n\n\n\n\n4\n1_primary\n1\n\n\n3\n2_secondary\n48\n\n\n1\n3_sixthform\n103\n\n\n0\n4_graduate\n152\n\n\n2\n5_postgrad\n60\n\n\n\n\n\n\n\n\ncounts_merged = merge_counts(counts_all, counts_requests, variable)\ncounts_merged\n\n\n\n\n\n\n\n\neducation\ncount_all\ncount_requests\nrequests_rate\n\n\n\n\n0\n1_primary\n59\n1\n1.694915\n\n\n1\n2_secondary\n4736\n48\n1.013514\n\n\n2\n3_sixthform\n10501\n103\n0.980859\n\n\n3\n4_graduate\n21165\n152\n0.718167\n\n\n4\n5_postgrad\n11797\n60\n0.508604\n\n\n\n\n\n\n\n\nchart = alt.Chart(counts_merged).mark_bar().encode(\n    x=variable,\n    y='requests_rate'\n)\n\nchart\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n\n\n\n\n\n\n\n\n\n# chart.save(f'../out/request-rate_{variable}.png', scale_factor=3.0)\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n\n\n\n\nsocial grade\n\nvariable = 'socGrade'\n\n\ncounts_all = get_total_counts(utterances, variable)\ncounts_all\n\n\n\n\n\n\n\n\nsocGrade\ncount\n\n\n\n\n3\nA\n6697\n\n\n1\nB\n13253\n\n\n2\nC1\n8888\n\n\n4\nD\n3071\n\n\n0\nE\n15915\n\n\n\n\n\n\n\n\ncounts_requests = get_var_counts_requests(utterances, variable)\ncounts_requests\n\n\n\n\n\n\n\n\nsocGrade\ncount\n\n\n\n\n3\nA\n32\n\n\n1\nB\n104\n\n\n2\nC1\n60\n\n\n4\nD\n23\n\n\n0\nE\n150\n\n\n\n\n\n\n\n\ncounts_merged = merge_counts(counts_all, counts_requests, variable)\ncounts_merged\n\n\n\n\n\n\n\n\nsocGrade\ncount_all\ncount_requests\nrequests_rate\n\n\n\n\n0\nA\n6697\n32\n0.477826\n\n\n1\nB\n13253\n104\n0.784728\n\n\n2\nC1\n8888\n60\n0.675068\n\n\n3\nD\n3071\n23\n0.748942\n\n\n4\nE\n15915\n150\n0.942507\n\n\n\n\n\n\n\n\nchart = alt.Chart(counts_merged).mark_bar().encode(\n    x=variable,\n    y='requests_rate'\n)\n\nchart\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n\n\n\n\n\n\n\n\n\n# chart.save(f'../out/request-rate_{variable}.png', scale_factor=3.0)\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n  col = df[col_name].apply(to_list_if_array, convert_dtype=False)",
    "crumbs": [
      "Social variables in the use of requests"
    ]
  },
  {
    "objectID": "evaluate-models.html",
    "href": "evaluate-models.html",
    "title": "calculate metrics for GPT classifications",
    "section": "",
    "text": "import pandas as pd\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n\nimport altair as alt\n\n\nresults = pd.read_csv('../out/utterances_gpt.csv')\n\n\nresults.value_counts('gpt_label')\n\ngpt_label\n0    44692\n1     5307\nName: count, dtype: int64\n\n\n\nmetrics_gpt = {}\n\nmetrics_gpt['model'] = 'GPT'\nmetrics_gpt['precision'] = precision_score(results[\"label\"], results[\"gpt_label\"])\nmetrics_gpt['recall'] = recall_score(results[\"label\"], results[\"gpt_label\"])\nmetrics_gpt['accuracy'] = accuracy_score(results[\"label\"], results[\"gpt_label\"])\nmetrics_gpt['f1'] = f1_score(results[\"label\"], results[\"gpt_label\"])\n\nmetrics_gpt = (pd.DataFrame(metrics_gpt, index=[0])\n           .round(2))\n\nmetrics_gpt\n\n\n\n\n\n\n\n\nmodel\nprecision\nrecall\naccuracy\nf1\n\n\n\n\n0\nGPT\n0.06\n0.78\n0.9\n0.11\n\n\n\n\n\n\n\n\ncompare metrics between GPT and BERT\n\nmetrics_bert = pd.read_csv('../in/stat-report/metrics_bert.csv')\n\n\nmetrics = pd.concat([metrics_gpt, metrics_bert])\nmetrics\n\n\n\n\n\n\n\n\nmodel\nprecision\nrecall\naccuracy\nf1\n\n\n\n\n0\nGPT\n0.06\n0.78\n0.90\n0.11\n\n\n0\nBERT\n0.21\n0.43\n0.94\n0.28\n\n\n\n\n\n\n\n\nmetrics_long = (metrics\n        .melt(id_vars='model', var_name='metric', value_name='score')\n        .sort_values('model')\n        )\n\nmetrics_long\n\n\n\n\n\n\n\n\nmodel\nmetric\nscore\n\n\n\n\n1\nBERT\nprecision\n0.21\n\n\n3\nBERT\nrecall\n0.43\n\n\n5\nBERT\naccuracy\n0.94\n\n\n7\nBERT\nf1\n0.28\n\n\n0\nGPT\nprecision\n0.06\n\n\n2\nGPT\nrecall\n0.78\n\n\n4\nGPT\naccuracy\n0.90\n\n\n6\nGPT\nf1\n0.11\n\n\n\n\n\n\n\n\nbars = alt.Chart(metrics_long).mark_bar().encode(\n    y=alt.Y(\"score\", title=''),\n    x=alt.X(\"model\", title=''),\n    color=alt.Color(\"model\", legend=None)\n)\n\ntext = alt.Chart(metrics_long).mark_text(dx=0, dy=-5, color='blue').encode(\n    y=\"score\",\n    x=\"model\",\n    detail='score',\n    text=alt.Text('score', format='.2f'),\n    color='model'\n)\n\nmetrics_chart = alt.layer(bars, text).facet(\n    column=alt.Column(\"metric\", sort=[\"precision\", \"recall\", \"f1\"])\n) \n\nmetrics_chart\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n\n\n\n\n\n\n\n\n\n# metrics_chart.save('../out/metrics_models.png', scale_factor=3.0)\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n  col = df[col_name].apply(to_list_if_array, convert_dtype=False)",
    "crumbs": [
      "calculate metrics for GPT classifications"
    ]
  },
  {
    "objectID": "classify-utterances.html",
    "href": "classify-utterances.html",
    "title": "utterance classification",
    "section": "",
    "text": "read data\n\nsource\n\nread_utterances\n\n read_utterances (fpath:str='../in/utterances_train.csv')\n\n\nutterances = read_utterances()\nutterances\n\n\n\n\n\n\n\n\ntext_id\nu_n\nu_who\ntext\nlabel\n\n\n\n\n0\nSC2T\n252\nS0392\nwe're all thinking of them now aren't we?\n0\n\n\n1\nST82\n298\nS0617\nvery new very modern\n0\n\n\n2\nS5QR\n10\nS0325\nI did I loved it\n0\n\n\n3\nSA2J\n2365\nS0622\nconsign charge the people who made the pipes f...\n0\n\n\n4\nSJLF\n429\nS0202\ncan I just point out this is for Cambridge Uni...\n1\n\n\n...\n...\n...\n...\n...\n...\n\n\n49995\nS6W8\n1065\nS0496\noh\n0\n\n\n49996\nSUVQ\n600\nS0198\nokay\n0\n\n\n49997\nSYHP\n2909\nS0262\nI think so\n0\n\n\n49998\nS6W8\n1065\nS0496\noh\n0\n\n\n49999\nSUVQ\n600\nS0198\nokay\n0\n\n\n\n\n50000 rows × 5 columns\n\n\n\n\nutterances.value_counts('label')\n\nlabel\n0    49617\n1      383\nName: count, dtype: int64\n\n\n\n\n\nset up model\n\nclass UtteranceClassification(BaseModel):\n    \"\"\"Identifying whether the utterance is a request or not.\"\"\"\n    gpt_label: int = Field(..., description=\"Whether this utterance is a request (0) or not a request (1)\")\n    gpt_justification: str = Field(..., description=\"Why you decided that it is a request or not a request.\")\n    gpt_confidence: int = Field(..., description=\"How confident you (ChatGPT) are in your decision, on an ordinal scale from 1 (very inconfident) to 5 (very confident)\")\n\n\ndef read_prompt(fpath: str) -&gt; str:\n    with open(fpath) as f:\n        prompt = f.read()\n    return prompt\n\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", read_prompt('../in/prompts/prompt_task.md')),\n        (\"system\", read_prompt('../in/prompts/prompt_few-shot-examples.md')),\n        (\"system\", read_prompt('../in/prompts/prompt_chain-of-thought.md')),\n        (\"human\", 'Please classify the following utterance: {input}')]\n)\n\nrunnable = create_structured_output_runnable(UtteranceClassification, llm, prompt)\n\n\n\nrun classification\n\nresults_list = []\n\nfor _, row in tqdm(utterances.iterrows(), total=len(utterances)):\n    result = runnable.invoke({\"input\": row['text']})\n    row_data = {\n        \"text_id\": row['text_id'],\n        \"u_n\": row['u_n'],\n        \"u_who\": row['u_who'],\n        \"text\": row['text'],\n        \"label\": row['label'],\n        \"gpt_label\": result.gpt_label,\n        \"gpt_justification\": result.gpt_justification,\n        \"gpt_confidence\": result.gpt_confidence       \n    }\n    results_list.append(row_data)\n    pd.DataFrame([row_data]).to_csv('../out/results_temp.csv', mode='a', header=False, index=False)\n\n\nresults_df = pd.DataFrame(results_list)",
    "crumbs": [
      "utterance classification"
    ]
  },
  {
    "objectID": "classification-errors.html",
    "href": "classification-errors.html",
    "title": "Analyse classification errors",
    "section": "",
    "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\nimport pandas as pd\n\n\nutterances = pd.read_csv('../in/stat-report/predictions_validation_config05.csv')\n\n\nutterances_errors = utterances.query('prediction != label')\nutterances_errors\n\n\n\n\n\n\n\n\nprediction\nlabel\nsentID\ntext\nspeakerID\n\n\n\n\n0\n1\n0\nS28F_558\nno no\nS0255\n\n\n1\n1\n0\nS28F_917\nyou want another I always find with wine\nS0315\n\n\n2\n1\n0\nS38V_150\nif you just put a hobbyhorse on this balcony\nS0192\n\n\n3\n1\n0\nS38V_1591\ncan they just stand up for now?\nS0192\n\n\n5\n1\n0\nS3LE_1234\nexcuse me oh sorry let me just take that away\nUNKFEMALE\n\n\n...\n...\n...\n...\n...\n...\n\n\n5742\n0\n1\nSTKH_451\nhave a look is it still recording?\nS0104\n\n\n5762\n0\n1\nSUC7_291\nI don't want the rest of that\nS0621\n\n\n6437\n0\n1\nSV28_20\ndo we have any pen and paper? because we haven...\nS0198\n\n\n6654\n0\n1\nSWY3_886\nlet him have a go\nS0391\n\n\n6731\n0\n1\nSYEF_718\noh dear be quick\nS0525\n\n\n\n\n158 rows × 5 columns\n\n\n\n\nutterances_errors.to_csv('../out/classification-errors.csv', index=False)",
    "crumbs": [
      "Analyse classification errors"
    ]
  }
]