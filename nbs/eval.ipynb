{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating metrics using `sklear` with `average='macro'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(fname, model):\n",
    "\tdf = pd.read_csv(fname)\n",
    "\tdf = df.dropna()\n",
    "\tprecision, recall, f1, _ = precision_recall_fscore_support(df[\"label\"], df[\"gpt_label\"], average=\"macro\")\n",
    "\tmetrics = pd.DataFrame({\n",
    "\t\t'model': model,\n",
    "\t\t'precision': precision,\n",
    "\t\t'recall': recall,\n",
    "\t\t'f1': f1\n",
    "\t}, index=[0])\n",
    "\treturn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.527336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.841187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.525738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model     metric     score\n",
       "1  gpt3.5  precision  0.527336\n",
       "3  gpt3.5     recall  0.841187\n",
       "5  gpt3.5         f1  0.525738"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_gpt = get_metrics('../out/results_temp.csv', 'gpt3.5')\n",
    "metrics_bert = pd.DataFrame({'model': 'BERT', 'precision': 0.21, 'recall': 0.43, 'f1': 0.28}, index=[0])\n",
    "\n",
    "metrics = pd.concat([metrics_bert, metrics_gpt])\n",
    "metrics = metrics.melt(id_vars=\"model\", var_name=\"metric\", value_name=\"score\")\n",
    "metrics.query('model == \"gpt3.5\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    bars = alt.Chart(metrics).mark_bar().encode(\n",
    "        y=alt.Y(\"score\", title=''),\n",
    "        x=alt.X(\"model\", title=''),\n",
    "        color=\"model\",\n",
    "    )\n",
    "\n",
    "    text = alt.Chart(metrics).mark_text(dx=0, dy=-5, color='blue').encode(\n",
    "        y=\"score\",\n",
    "        x=\"model\",\n",
    "        detail='score',\n",
    "        text=alt.Text('score', format='.2f'),\n",
    "        color='model'\n",
    "    )\n",
    "\n",
    "    chart = alt.layer(bars, text).facet(\n",
    "        column=alt.Column(\"metric\", sort=[\"precision\", \"recall\", \"f1\"])\n",
    "    ) \n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1315ab3d9b7347008377aab5f429043e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1315ab3d9b7347008377aab5f429043e.vega-embed details,\n",
       "  #altair-viz-1315ab3d9b7347008377aab5f429043e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1315ab3d9b7347008377aab5f429043e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1315ab3d9b7347008377aab5f429043e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1315ab3d9b7347008377aab5f429043e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.14.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.14.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9786472beffbc037dd1e7ce2c9a96138\"}, \"facet\": {\"column\": {\"field\": \"metric\", \"sort\": [\"precision\", \"recall\", \"f1\"], \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model\", \"title\": \"\", \"type\": \"nominal\"}, \"y\": {\"field\": \"score\", \"title\": \"\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"color\": \"blue\", \"dx\": 0, \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model\", \"type\": \"nominal\"}, \"detail\": {\"field\": \"score\", \"type\": \"quantitative\"}, \"text\": {\"field\": \"score\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"model\", \"type\": \"nominal\"}, \"y\": {\"field\": \"score\", \"type\": \"quantitative\"}}}]}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.14.1.json\", \"datasets\": {\"data-9786472beffbc037dd1e7ce2c9a96138\": [{\"model\": \"BERT\", \"metric\": \"precision\", \"score\": 0.21}, {\"model\": \"gpt3.5\", \"metric\": \"precision\", \"score\": 0.5273359784249328}, {\"model\": \"BERT\", \"metric\": \"recall\", \"score\": 0.43}, {\"model\": \"gpt3.5\", \"metric\": \"recall\", \"score\": 0.8411873949109316}, {\"model\": \"BERT\", \"metric\": \"f1\", \"score\": 0.28}, {\"model\": \"gpt3.5\", \"metric\": \"f1\", \"score\": 0.5257380316061205}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart.save('../out/metrics_50k.png', scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating metrics manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = pd.read_csv('../out/50k_labelled_gpt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = len(utterances.query('gpt_label == 1 & label == 1'))\n",
    "false_pos = len(utterances.query('gpt_label == 1 & label == 0'))\n",
    "true_neg = len(utterances.query('gpt_label == 0 & label == 0'))\n",
    "false_neg = len(utterances.query('gpt_label == 0 & label == 1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = true_pos / (true_pos + false_pos)\n",
    "recall = true_pos / (true_pos + false_neg)\n",
    "accuracy = (true_pos + true_neg) / (true_pos + false_pos + true_neg + false_neg)\n",
    "f_one = 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  precision  recall  accuracy     F1\n",
       "0  GPT3.5      0.057   0.783     0.898  0.105"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_metrics_manual = pd.DataFrame({\n",
    "\t'model': 'GPT3.5',\n",
    "\t'precision': round(precision, 3),\n",
    "\t'recall': round(recall, 3),\n",
    "\t'accuracy': round(accuracy, 3),\n",
    "\t'F1': round(f_one, 3)\n",
    "}, index=[0])\n",
    "\n",
    "gpt_metrics_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  precision  recall  accuracy    F1\n",
       "0  BERT       0.27    0.39      0.98  0.32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_metrics = pd.DataFrame({\n",
    "\t'model': 'BERT',\n",
    "\t'precision': 0.27,\n",
    "\t'recall': 0.39,\n",
    "\t'accuracy': 0.98,\n",
    "\t'F1': 0.32\n",
    "}, index=[0])\n",
    "\n",
    "bert_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_manual_comparison = pd.concat([gpt_metrics_manual, bert_metrics])\n",
    "metrics_manual_comparison = metrics_manual_comparison.melt(id_vars=\"model\", var_name=\"metric\", value_name=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-00e57e341d7541a0a943bd0cf7cbeda6.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-00e57e341d7541a0a943bd0cf7cbeda6.vega-embed details,\n",
       "  #altair-viz-00e57e341d7541a0a943bd0cf7cbeda6.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-00e57e341d7541a0a943bd0cf7cbeda6\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-00e57e341d7541a0a943bd0cf7cbeda6\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-00e57e341d7541a0a943bd0cf7cbeda6\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.14.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.14.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-947b31551f305b1605907f1cb5745409\"}, \"facet\": {\"column\": {\"field\": \"metric\", \"sort\": [\"precision\", \"recall\", \"f1\"], \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model\", \"title\": \"\", \"type\": \"nominal\"}, \"y\": {\"field\": \"score\", \"title\": \"\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"color\": \"blue\", \"dx\": 0, \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model\", \"type\": \"nominal\"}, \"detail\": {\"field\": \"score\", \"type\": \"quantitative\"}, \"text\": {\"field\": \"score\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"model\", \"type\": \"nominal\"}, \"y\": {\"field\": \"score\", \"type\": \"quantitative\"}}}]}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.14.1.json\", \"datasets\": {\"data-947b31551f305b1605907f1cb5745409\": [{\"model\": \"GPT3.5\", \"metric\": \"precision\", \"score\": 0.057}, {\"model\": \"BERT\", \"metric\": \"precision\", \"score\": 0.27}, {\"model\": \"GPT3.5\", \"metric\": \"recall\", \"score\": 0.783}, {\"model\": \"BERT\", \"metric\": \"recall\", \"score\": 0.39}, {\"model\": \"GPT3.5\", \"metric\": \"accuracy\", \"score\": 0.898}, {\"model\": \"BERT\", \"metric\": \"accuracy\", \"score\": 0.98}, {\"model\": \"GPT3.5\", \"metric\": \"F1\", \"score\": 0.105}, {\"model\": \"BERT\", \"metric\": \"F1\", \"score\": 0.32}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_plot = plot_metrics(metrics_manual_comparison)\n",
    "metrics_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/requestgpt/lib/python3.11/site-packages/altair/utils/core.py:410: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    }
   ],
   "source": [
    "metrics_plot.save('../out/metrics_50k_binary.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using `sklearn` and `average = 'binary'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05652911249293386\n",
      "0.783289817232376\n",
      "0.1054481546572935\n"
     ]
    }
   ],
   "source": [
    "precision_skl, recall_skl, f1_skl, _ = precision_recall_fscore_support(\n",
    "\tutterances['label'], utterances['gpt_label'], \n",
    "\taverage='binary'\n",
    "\t)\n",
    "\n",
    "print(precision_skl, recall_skl, f1_skl, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05652911249293386"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(utterances['label'], utterances['gpt_label'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "requestgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
