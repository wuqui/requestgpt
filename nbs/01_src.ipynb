{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(fp='../in/utterances_requests_50k_labeled.csv'):\n",
    "\tdf = pd.read_csv('../in/utterances_requests_50k_labeled.csv')\n",
    "\t# in the `label` column, replace `1.0` with `1` and `NaN` with `0`\n",
    "\tdf[\"label\"] = df[\"label\"].fillna(0).astype(int)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sample(df, n):\n",
    "\tsample_dfs = []\n",
    "\tfor label in [0, 1]:\n",
    "\t\tsample_df = (df\n",
    "\t\t.query(f'label == {label}')\n",
    "\t\t.sample(int(n / 3) + 1)\n",
    "\t\t)\n",
    "\t\tsample_dfs.append(sample_df)\n",
    "\treturn pd.concat(sample_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "#| export\n",
    "def get_api_key():\n",
    "\t# Load the environment variables from the .env file\n",
    "\tload_dotenv()\n",
    "\t# Get the value of the OPENAI_API_KEY environment variable\n",
    "\treturn os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specify output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class output_request(BaseModel):\n",
    "    \"\"\"output schema for request\"\"\"\n",
    "    label: int = Field(description=\"`0` if not a request, `1` if a request\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_model(ai, df):\n",
    "\ttqdm.pandas()\n",
    "\tai_labels = df[\"text\"].progress_apply(lambda x: ai(str(x), output_schema=output_request))\n",
    "\t# Unpack the dictionary in `gpt_dict` column into separate columns and prefix every column with `gpt_`\n",
    "\treturn pd.concat([df, ai_labels.apply(pd.Series).add_prefix('gpt_')], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
