{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(fp: str='../in/utterances_requests_50k_labeled.csv'):\n",
    "\tdf = pd.read_csv(fp)\n",
    "\t# in the `label` column, replace `NaN` with `0` and `1.0` with `1`\n",
    "\tdf['label'] = df['label'].fillna(0).astype(int)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    49617\n",
       "1      383\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sample(df, requests_n: int):\n",
    "\trequests = df.query('label == 1').sample(requests_n, random_state=23) \n",
    "\tnon_requests = df.query('label == 0').sample(requests_n, random_state=23)\n",
    "\treturn pd.concat([requests, non_requests])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "#| export\n",
    "def get_api_key():\n",
    "\t# Load the environment variables from the .env file\n",
    "\tload_dotenv()\n",
    "\t# Get the value of the OPENAI_API_KEY environment variable\n",
    "\treturn os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specify output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class output_request(BaseModel):\n",
    "    \"\"\"output schema for request\"\"\"\n",
    "    label: int = Field(description='`0` if not a request, `1` if a request')\n",
    "    justification: str = Field(description='justification for why or why not the given utterance was classified as a request')\n",
    "    confidence: int = Field(description='''\n",
    "        give a score for how confident you are in your classification of this utterance as a request/non-request,\n",
    "        on a scale of 1 to 5, where 1 is not confident at all and 5 is very confident''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_model(ai, df):\n",
    "\ttqdm.pandas()\n",
    "\tai_labels = df['text'].progress_apply(lambda x: ai(str(x), output_schema=output_request))\n",
    "\t# Unpack the dictionary in `gpt_dict` column into separate columns and prefix every column with `gpt_`\n",
    "\treturn pd.concat([df, ai_labels.apply(pd.Series).add_prefix('gpt_')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### incrementally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpleaichat import AIChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "model='gpt-3.5-turbo'\n",
    "# model='gpt-4'\n",
    "\n",
    "ai = AIChat(model, system=prompt,\n",
    "    console=False, save_messages=False, params={\"temperature\": 0.0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests_n = len(df.query('label == 1'))\n",
    "requests_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = get_sample(df, requests_n)\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_model_incremental(ai, df, batch_size=100, results_file=\"intermediate_results.csv\"):\n",
    "    # Check if results file exists\n",
    "    if os.path.exists(results_file):\n",
    "        # Load previously processed results\n",
    "        processed_df = pd.read_csv(results_file)\n",
    "        last_index = processed_df.index[-1] if not processed_df.empty else -1\n",
    "    else:\n",
    "        processed_df = pd.DataFrame()\n",
    "        last_index = -1\n",
    "\n",
    "    # If everything is already processed\n",
    "    if last_index >= len(df) - 1:\n",
    "        return processed_df\n",
    "\n",
    "    # Calculate the number of batches\n",
    "    total_batches = (len(df) - last_index - 1) // batch_size + 1\n",
    "\n",
    "    with tqdm(total=total_batches, desc=\"Overall Progress\") as pbar_outer:\n",
    "        # Process in batches\n",
    "        for start in range(last_index + 1, len(df), batch_size):\n",
    "            end = start + batch_size\n",
    "            batch = df.iloc[start:end]\n",
    "            \n",
    "            # Inner progress bar for batch processing\n",
    "            ai_labels_list = []\n",
    "            for text in tqdm(batch['text'], desc=\"Batch Progress\", leave=False):\n",
    "                ai_labels_list.append(ai(str(text), output_schema=output_request))\n",
    "                \n",
    "            # Convert ai_labels_list into a DataFrame\n",
    "            ai_labels_df = pd.DataFrame(ai_labels_list)\n",
    "\n",
    "            # Reset indices before concatenation\n",
    "            batch = batch.reset_index(drop=True)\n",
    "            ai_labels_df = ai_labels_df.reset_index(drop=True)\n",
    "\n",
    "            result_batch = pd.concat([batch, ai_labels_df.add_prefix('gpt_')], axis=1)\n",
    "\n",
    "            # Append to processed_df and save\n",
    "            processed_df = pd.concat([processed_df, result_batch], axis=0)\n",
    "            processed_df.to_csv(results_file, index=False)\n",
    "\n",
    "            # Update the outer progress bar\n",
    "            pbar_outer.update(1)\n",
    "\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_model_incremental(ai, df_test, batch_size=10, results_file=\"../out/intermediate_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find few-show examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay Barcelona to Brussels I didn't do\n",
      "mm\n",
      "hmm\n",
      "satellite\n",
      "mm\n",
      "Cos how do you go down to Devon usually?\n",
      "and they they'd cut they snipped it?\n"
     ]
    }
   ],
   "source": [
    "for t in (df\n",
    " .query('label == 0')\n",
    " .sample(7)\n",
    " .loc[:, 'text']\n",
    "):\n",
    "\tprint(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
