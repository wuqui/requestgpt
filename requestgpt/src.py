# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_src.ipynb.

# %% auto 0
__all__ = ['load_data', 'get_sample', 'get_api_key', 'output_request', 'run_model']

# %% ../nbs/01_src.ipynb 4
import pandas as pd

# %% ../nbs/01_src.ipynb 5
def load_data(fp='../in/utterances_requests_50k_labeled.csv'):
	df = pd.read_csv('../in/utterances_requests_50k_labeled.csv')
	# in the `label` column, replace `1.0` with `1` and `NaN` with `0`
	df["label"] = df["label"].fillna(0).astype(int)
	return df

# %% ../nbs/01_src.ipynb 7
def get_sample(df, n):
	sample_dfs = []
	for label in [0, 1]:
		sample_df = (df
		.query(f'label == {label}')
		.sample(int(n / 3) + 1)
		)
		sample_dfs.append(sample_df)
	return pd.concat(sample_dfs)

# %% ../nbs/01_src.ipynb 10
from dotenv import load_dotenv
import os

# %% ../nbs/01_src.ipynb 11
def get_api_key():
	# Load the environment variables from the .env file
	load_dotenv()
	# Get the value of the OPENAI_API_KEY environment variable
	return os.getenv("OPENAI_API_KEY")

# %% ../nbs/01_src.ipynb 13
from pydantic import BaseModel, Field

class output_request(BaseModel):
    """output schema for request"""
    label: int = Field(description="`0` if not a request, `1` if a request")

# %% ../nbs/01_src.ipynb 15
from tqdm import tqdm

def run_model(ai, df):
	tqdm.pandas()
	ai_labels = df["text"].progress_apply(lambda x: ai(str(x), output_schema=output_request))
	# Unpack the dictionary in `gpt_dict` column into separate columns and prefix every column with `gpt_`
	return pd.concat([df, ai_labels.apply(pd.Series).add_prefix('gpt_')], axis=1)
